{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07fb362a",
   "metadata": {},
   "source": [
    "## File per creare correttamente la matrice con i 30 anni già con la pca applicata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd64558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import shapefile as shp\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib\n",
    "import utils.data_processing\n",
    "import utils.visualization\n",
    "importlib.reload(utils.data_processing)\n",
    "importlib.reload(utils.visualization)\n",
    "\n",
    "# Import the functions \n",
    "from utils.data_processing import prepare_data_matrix, apply_global_standardization, perform_incremental_pca\n",
    "\n",
    "from utils.visualization import plot_variance, scatter_plot_2d,scatter_plot_3d,  add_country_boundaries\n",
    "from utils.visualization import visualization_pca_coefficient\n",
    "\n",
    "from utils.clusterization import kmeans, elbow_analysis, gap_statistic, silhouette_analysis, davies_bouldin_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65df318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the combined dataset:\n",
      "   • Variables: ['z', 't']\n",
      "   • Coordinates: ['number', 'time', 'step', 'isobaricInhPa', 'latitude', 'longitude', 'valid_time']\n",
      "   • Shape: FrozenMappingWarningOnValuesAccess({'time': 5479, 'isobaricInhPa': 2, 'latitude': 201, 'longitude': 321})\n"
     ]
    }
   ],
   "source": [
    "# First file\n",
    "ds1 = xr.open_dataset('../era5_1994_2008.grib', engine='cfgrib')\n",
    "ds1_even = ds1.isel(time=slice(0, None, 2))  # select only the even rows\n",
    "del ds1  \n",
    "gc.collect()\n",
    "\n",
    "# Second file\n",
    "ds2 = xr.open_dataset('../era5_2009_2023.grib', engine='cfgrib')\n",
    "ds2_even = ds2.isel(time=slice(0, None, 2))  \n",
    "del ds2  \n",
    "gc.collect()\n",
    "\n",
    "# Merge the two datasets\n",
    "ds_even = xr.concat([ds1_even, ds2_even], dim='time')\n",
    "del ds1_even, ds2_even\n",
    "gc.collect()\n",
    "\n",
    "print(\"Overview of the combined dataset:\")\n",
    "print(f\"   • Variables: {list(ds_even.data_vars.keys())}\")\n",
    "print(f\"   • Coordinates: {list(ds_even.coords.keys())}\")\n",
    "print(f\"   • Shape: {ds_even.dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee4a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "Dataset saved as era5_30years_even.nc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ds_even['z'].dtype)\n",
    "print(ds_even['t'].dtype)\n",
    "\n",
    "ds_even = ds_even.astype('float32')\n",
    "\n",
    "# Salva il dataset combinato in formato NetCDF (consigliato per xarray)\n",
    "ds_even.to_netcdf(\"era5_30years_even.nc\")\n",
    "print(\"Dataset saved as era5_30years_even.nc\")\n",
    "del ds_even\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d309a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Dataset - Variables: ['z', 't']\n",
      "Dimensions: {'time': 5479, 'pressure_z': 1, 'latitude': 201, 'longitude': 321, 'pressure_t': 1}\n",
      "Time range: 1994-01-01T00:00:00.000000000 to 2023-12-30T00:00:00.000000000\n",
      "<xarray.Dataset> Size: 3GB\n",
      "Dimensions:     (time: 5479, pressure_z: 1, latitude: 201, longitude: 321,\n",
      "                 pressure_t: 1)\n",
      "Coordinates:\n",
      "    number      int64 8B 0\n",
      "  * time        (time) datetime64[ns] 44kB 1994-01-01 1994-01-03 ... 2023-12-30\n",
      "    step        timedelta64[ns] 8B 00:00:00\n",
      "  * pressure_z  (pressure_z) float64 8B 500.0\n",
      "  * latitude    (latitude) float64 2kB 70.0 69.75 69.5 69.25 ... 20.5 20.25 20.0\n",
      "  * longitude   (longitude) float64 3kB -40.0 -39.75 -39.5 ... 39.5 39.75 40.0\n",
      "    valid_time  (time) datetime64[ns] 44kB 1994-01-01 1994-01-03 ... 2023-12-30\n",
      "  * pressure_t  (pressure_t) float64 8B 850.0\n",
      "Data variables:\n",
      "    z           (time, pressure_z, latitude, longitude) float32 1GB ...\n",
      "    t           (time, pressure_t, latitude, longitude) float32 1GB ...\n",
      "-----------------\n",
      "Processing z...\n",
      "     → z: ('time', 'pressure_z', 'latitude', 'longitude') → (5479, 64521)\n",
      "Processing t...\n",
      "     → t: ('time', 'pressure_t', 'latitude', 'longitude') → (5479, 64521)\n",
      "\n",
      "Combined matrix shape: (5479, 129042)\n"
     ]
    }
   ],
   "source": [
    "# demarcare la cella di prima se torno ai dati di prima (cella per selezionare le variabili)\n",
    "# nel caricamento dati devo mettere il file 'era5_2000_2004.grib'\n",
    "# - Geopotenziale a 500 hPa\n",
    "# - Temperatura a 850 hPa\n",
    "\n",
    "# Create a new dataset\n",
    "ds_filtered = xr.Dataset()\n",
    "\n",
    "ds_even = xr.open_dataset(\"../era5_30years_even.nc\")\n",
    "# Add the geopotential at 500 hPa\n",
    "z_500 = ds_even['z'].sel(isobaricInhPa=[500])\n",
    "\n",
    "# Add the temperature at 850 hPa\n",
    "t_850 = ds_even['t'].sel(isobaricInhPa=[850])\n",
    "\n",
    "# Rename the coordinates in order to avoid conflicts\n",
    "z_500 = z_500.rename({'isobaricInhPa': 'pressure_z'})\n",
    "t_850 = t_850.rename({'isobaricInhPa': 'pressure_t'})\n",
    "\n",
    "\n",
    "# Combine everything into the filtered dataset\n",
    "ds_filtered = xr.Dataset({\n",
    "    'z': z_500,\n",
    "    't': t_850\n",
    "})\n",
    "\n",
    "# Filter the dataset for season's months \n",
    "#season_months = [1, 2, 3, 4, 10 ,11, 12]  \n",
    "#ds_filtered = ds_filtered.sel(time=ds_filtered['time.month'].isin(season_months))\n",
    "\n",
    "\n",
    "print(f\"Filtered Dataset - Variables: {list(ds_filtered.data_vars.keys())}\")\n",
    "print(f\"Dimensions: {dict(ds_filtered.dims)}\")\n",
    "print(f\"Time range: {ds_filtered.time.min().values} to {ds_filtered.time.max().values}\")\n",
    "\n",
    "print(ds_filtered)  \n",
    "\n",
    "print(\"-----------------\")\n",
    "    \n",
    "X, data_matrices = prepare_data_matrix(ds_filtered) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90281af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOBAL STANDARDIZATION\n",
      "Before standardization:\n",
      " • Global mean: 27779.39m\n",
      " • Global std: 27544.21m\n",
      "Dataset shape: (5479, 129042)\n",
      "After standardization:\n",
      " • New global mean: 0.000253\n",
      " • New global std: 1.000214\n",
      " • Sample min: -1.000\n",
      " • Sample max: 1.138\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOBAL STANDARDIZATION\")\n",
    "\n",
    "# Applica standardizzazione globale usando la funzione da utils\n",
    "X, global_mean, global_std = apply_global_standardization(X)\n",
    "\n",
    "print(\"Before standardization:\")\n",
    "print(f\" • Global mean: {global_mean:.2f}m\")\n",
    "print(f\" • Global std: {global_std:.2f}m\")\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "\n",
    "print(\"After standardization:\")\n",
    "print(f\" • New global mean: {X.mean():.6f}\")\n",
    "print(f\" • New global std: {X.std():.6f}\")\n",
    "\n",
    "# Verify some sample statistics\n",
    "print(f\" • Sample min: {X.min():.3f}\")\n",
    "print(f\" • Sample max: {X.max():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a46fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"global_mean_30y.npy\", global_mean)\n",
    "np.save(\"global_std_30y.npy\", global_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6acfad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCREMENTAL PCA ANALYSIS\n",
      "   • Target components: 20\n",
      "   • Batch size: 100\n",
      "Original shape: (5479, 129042)\n",
      "PCA shape: (5479, 20)\n",
      "\n",
      "First 10 components variance: [0.49234794 0.11733436 0.09122786 0.07440938 0.05198909 0.03327221\n",
      " 0.0219017  0.02104583 0.01374796 0.01086561]\n",
      "Total explained variance 20 components cumulative: 0.976\n"
     ]
    }
   ],
   "source": [
    "print(\"INCREMENTAL PCA ANALYSIS\")\n",
    "\n",
    "n_components = 20  # Reduced to 20 components for safety with batch processing\n",
    "batch_size = 100    # Increased batch size to accommodate more components\n",
    "\n",
    "print(f\"   • Target components: {n_components}\")\n",
    "print(f\"   • Batch size: {batch_size}\")\n",
    " \n",
    "X_pca, ipca, explained_variance_ratio, cumulative_variance = perform_incremental_pca(X, n_components=n_components, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72fc811d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ipca_30y.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the PCA model\n",
    "\n",
    "joblib.dump(ipca, \"ipca_30y.pkl\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
