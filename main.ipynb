{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09e8e9a",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering Methods for Meteorological European Configurations/ Patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275b925",
   "metadata": {},
   "source": [
    "<span style=\"color: yellow;\"> - prendo solo un sub set dei dati per la velocità (fatto in -> 1.1), poi sarà da prendre tutto il dataset (30.07.25)  </span>  \n",
    "<span style=\"color: yellow;\">- vedere se togliere i percentili in 1.1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "595b08ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, jarque_bera, anderson\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.gofplots import qqplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922c18b7",
   "metadata": {},
   "source": [
    "## 1 Caricamento Dati e Analisi Iniziale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baa42acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ds = xr.open_dataset('era5_2000_2004.grib', engine= 'cfgrib') # XArray DataSet\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "335f3534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of the dataset:\n",
      "   • Variabili: ['z', 't', 'u', 'v']\n",
      "   • Coordinate: ['number', 'time', 'step', 'isobaricInhPa', 'latitude', 'longitude', 'valid_time']\n"
     ]
    }
   ],
   "source": [
    "print(\"Overview of the dataset:\")\n",
    "print(f\"   • Variabili: {list(ds.data_vars.keys())}\")\n",
    "print(f\"   • Coordinate: {list(ds.coords.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97965aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension details:\n",
      "   • Latitude: 201 points (20.0° - 70.0°)\n",
      "   • Longitude: 321 points (-40.0° - 40.0°)\n",
      "   • Time: 1827 steps (2000-01-01 - 2004-12-31)\n",
      "   • Pressure levels: 3 levels ([np.float64(850.0), np.float64(500.0), np.float64(250.0)] hPa)\n",
      "Variables in the dataset:\n",
      "   • z: ('time', 'isobaricInhPa', 'latitude', 'longitude') - Geopotential\n",
      "     └─ Units: m**2 s**-2\n",
      "   • t: ('time', 'isobaricInhPa', 'latitude', 'longitude') - Temperature\n",
      "     └─ Units: K\n",
      "   • u: ('time', 'isobaricInhPa', 'latitude', 'longitude') - U component of wind\n",
      "     └─ Units: m s**-1\n",
      "   • v: ('time', 'isobaricInhPa', 'latitude', 'longitude') - V component of wind\n",
      "     └─ Units: m s**-1\n"
     ]
    }
   ],
   "source": [
    "# Dimenision details\n",
    "print(\"Dimension details:\")\n",
    "if 'latitude' in ds.dims:\n",
    "    print(f\"   • Latitude: {ds.dims['latitude']} points ({ds.latitude.min().values:.1f}° - {ds.latitude.max().values:.1f}°)\")\n",
    "if 'longitude' in ds.dims:\n",
    "    print(f\"   • Longitude: {ds.dims['longitude']} points ({ds.longitude.min().values:.1f}° - {ds.longitude.max().values:.1f}°)\")\n",
    "if 'time' in ds.dims:\n",
    "    print(f\"   • Time: {ds.dims['time']} steps ({pd.to_datetime(ds.time.values[0]).strftime('%Y-%m-%d')} - {pd.to_datetime(ds.time.values[-1]).strftime('%Y-%m-%d')})\")\n",
    "if 'isobaricInhPa' in ds.dims:\n",
    "    print(f\"   • Pressure levels: {ds.dims['isobaricInhPa']} levels ({list(ds.isobaricInhPa.values)} hPa)\")\n",
    "\n",
    "#Variables \n",
    "print(\"Variables in the dataset:\")\n",
    "for var in ds.data_vars:\n",
    "    var_data = ds[var]\n",
    "    print(f\"   • {var}: {var_data.dims} - {var_data.attrs.get('long_name', 'N/A')}\")\n",
    "    print(f\"     └─ Units: {var_data.attrs.get('units', 'N/A')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd087867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIMENSIONALITY:\n",
      "   • Spatial points: 64521\n",
      "   • Total features per timestep: 774,252\n",
      "   • Temporal samples: 1827\n"
     ]
    }
   ],
   "source": [
    "# Total dimensionality\n",
    "total_spatial_points = 1\n",
    "for dim in ['latitude', 'longitude']:\n",
    "    if dim in ds.dims:\n",
    "        total_spatial_points *= ds.dims[dim]\n",
    "\n",
    "total_features = len(ds.data_vars) * ds.dims.get('isobaricInhPa', 1) * total_spatial_points\n",
    "print(\"DIMENSIONALITY:\")\n",
    "print(f\"   • Spatial points: {total_spatial_points}\")\n",
    "print(f\"   • Total features per timestep: {total_features:,}\")\n",
    "print(f\"   • Temporal samples: {ds.dims.get('time', 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d1633",
   "metadata": {},
   "source": [
    "Spatial points: punti griglia nello spazio. \n",
    "La regione osservata è suddivisa in una griglia regolare (0.25° x 0.25°), per ogni punto nella grigli avengono misurate le variabili\n",
    "\n",
    "Total features per timestep: numero di variabili (features) in totale in ogni istante di tempo\n",
    "\n",
    "Temporal samples: punti temporali nel dataset (365 giorni per 5 anni)\n",
    "\n",
    "Posso trasformarlo in una matrice per il clustering:  \n",
    "shape = (temporal_samples, total_features_per_timestep)\n",
    "       = (1827, 774252)  \n",
    "Ogni riga = una mappa meteorologica\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5e19da",
   "metadata": {},
   "source": [
    "### 1.1 Check quality in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e70968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the dataset for a specific time range (POI DA TOGLIERE)\n",
    "#ds = ds.sel(time=slice(\"2000-01-01\", \"2001-12-31\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a4083f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING VALUES:\n",
      "    z: 0 missing (0.00%)\n",
      "    t: 0 missing (0.00%)\n",
      "    u: 0 missing (0.00%)\n",
      "    v: 0 missing (0.00%)\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_values(dataset):\n",
    "    \"\"\"Analizzes missing values for each variable\"\"\"\n",
    "    missing_info = {}\n",
    "    \n",
    "    for var in dataset.data_vars:\n",
    "        data = dataset[var]\n",
    "        total_values = data.size\n",
    "        missing_count = np.isnan(data.values).sum()\n",
    "        missing_percent = (missing_count / total_values) * 100\n",
    "        \n",
    "        missing_info[var] = {\n",
    "            'count': missing_count,\n",
    "            'percentage': missing_percent,\n",
    "            'total': total_values\n",
    "        }\n",
    "    \n",
    "    return missing_info\n",
    "\n",
    "print(\"MISSING VALUES:\")\n",
    "missing_analysis = analyze_missing_values(ds)\n",
    "\n",
    "for var, info in missing_analysis.items():\n",
    "    print(f\"    {var}: {info['count']:,} missing ({info['percentage']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f4c385",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7856d465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATISTICS:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Z:\n",
      "      • Min: 7495.887\n",
      "      • Max: 108808.312\n",
      "      • Mean: 57405.691\n",
      "      • Std: 36090.105\n",
      "      • Percentiles [25%, 50%, 75%]: [ 15097.1484375  55659.46875   100139.4375   ]\n",
      " T:\n",
      "      • Min: 198.893\n",
      "      • Max: 308.547\n",
      "      • Mean: 252.359\n",
      "      • Std: 24.976\n",
      "      • Percentiles [25%, 50%, 75%]: [226.2230072  255.91355896 272.93847656]\n",
      " U:\n",
      "      • Min: -63.877\n",
      "      • Max: 112.808\n",
      "      • Mean: 8.984\n",
      "      • Std: 13.904\n",
      "      • Percentiles [25%, 50%, 75%]: [-0.31930542  6.58242798 16.01531982]\n",
      " V:\n",
      "      • Min: -91.157\n",
      "      • Max: 89.342\n",
      "      • Mean: -0.238\n",
      "      • Std: 11.834\n",
      "      • Percentiles [25%, 50%, 75%]: [-5.98008728 -0.32400513  5.86112976]\n"
     ]
    }
   ],
   "source": [
    "print(\"STATISTICS:\")\n",
    "for var in ds.data_vars:\n",
    "    data = ds[var].values\n",
    "    valid_data = data[~np.isnan(data)]\n",
    "    \n",
    "    if len(valid_data) > 0:\n",
    "        print(f\" {var.upper()}:\")\n",
    "        print(f\"      • Min: {valid_data.min():.3f}\")\n",
    "        print(f\"      • Max: {valid_data.max():.3f}\")\n",
    "        print(f\"      • Mean: {valid_data.mean():.3f}\")\n",
    "        print(f\"      • Std: {valid_data.std():.3f}\")\n",
    "        print(f\"      • Percentiles [25%, 50%, 75%]: {np.percentile(valid_data, [25, 50, 75])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b57bef",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d63352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e916de27",
   "metadata": {},
   "source": [
    "## 2 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341b0a9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grib_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
